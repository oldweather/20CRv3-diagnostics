
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
        <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Extracting data from 20CRv3 &#8212; Tests and analyses of version 3 of the Twentieth Century Reanalysis</title>
    <link rel="stylesheet" href="../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tropical Storms" href="../tropical-storms/tropical_storms.html" />
    <link rel="prev" title="How to use this dataset" href="../instructions.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="../tropical-storms/tropical_storms.html" title="Tropical Storms"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../instructions.html" title="How to use this dataset"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">20CRv3</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/t2t3.png" alt="Logo"/>
            </a></p>
<h3><a href="../index.html">Table Of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../credits.html">Authors and acknowledgements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../instructions.html">How to re-use this</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Extracting data from 20CRv3</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tropical-storms/tropical_storms.html">Tropical Storms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../european_windstorms/european_windstorms.html">European windstorms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extreme_months/extreme_months.html">Extreme months</a></li>
</ul>
<h3><a href="https://github.com/oldweather/20CRv3-diagnostics">Get a copy</a></h3>

<ul>
<li><a href="https://github.com/oldweather/20CRv3-diagnostics"
           rel="nofollow">Github repository</a></li>
</ul>

<h3>Found a bug, or have a suggestion?</h3>

Please <a href="https://github.com/oldweather/20CRv3-diagnostics/issues/new">raise an issue</a>.
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="extracting-data-from-20crv3">
<h1>Extracting data from 20CRv3<a class="headerlink" href="#extracting-data-from-20crv3" title="Permalink to this headline">¶</a></h1>
<p>The 20CRv2c data are <a class="reference external" href="http://portal.nersc.gov/project/20C_Reanalysis/">available</a> as netCDF files, each containing 3- or 6-hourly data, for a single variable, for all ensemble members, for a year. I have <a class="reference external" href="https://brohan.org/IRData">software that uses data in this format</a>, so I aim to produce v3 data in a similar format. The main difference is that there is much more data from v3 (higher resolution, more ensemble members, always 3-hourly) so I make files for each month, not each year.</p>
<p>v3 does not exist yet, we identify proto-v3 data by its <em>run number</em>. The two run numbers I’ve looked at so far are 451 and 452. Run numbers in the 400s are from the v3 model and this data extraction method should work for any of them.</p>
<p>The data extraction process is in four steps:</p>
<ol class="arabic simple">
<li>Find the model output files for a month</li>
<li>Copy them to my own $SCRATCH</li>
<li>Copy all the output for a single variable to one grib file and convert it to netCDF</li>
<li>Assemble the observations files</li>
</ol>
<div class="section" id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h2>
<p>All the scripts need to be run on <a class="reference external" href="http://www.nersc.gov/users/computational-systems/cori/">Cori</a>, from an account that’s part of the 20CR group.
The conversion scripts use the NCAR library and the netcdf operators, these need to be loaded as modules:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>module load ncar
module load nco
</pre></div>
</div>
<p>Look for the scripts in directory ‘/global/homes/p/pbrohan/Projects/20CRv3-diagnostics/extract_data/’ (or <a class="reference external" href="https://github.com/oldweather/20CRv3-diagnostics">clone this repository</a>).</p>
</div>
<div class="section" id="find-the-model-output-files">
<h2>Find the model output files<a class="headerlink" href="#find-the-model-output-files" title="Permalink to this headline">¶</a></h2>
<p>The model output for a single assimilation step (6-hour period) is all put in the same directory, with a name formated as YYYYMMDDHH, so directory 1928031206 contains data for the 6-hour period starting at 6a.m (UTC) on March 12 1928. There are 4 assimilation steps each day (0,6,12,18 hours). The analysis is run in many streams (usually of 5-years duration) - a different stream is started every 5 years. So the model outputs are uniquely identified by their <em>run number</em>, their <em>start year</em>, and their <em>date</em>: directory ‘ensda_451_1899/1903102618’ contains the data for run 451, stream starting in 1899, valid at 6pm UTC on 26 October 1903.</p>
<p>The freshest model output is in the $SCRATCH directory of whoever is doing the run (Chesley or Gil):</p>
<ul class="simple">
<li>/global/cscratch1/sd/cmccoll/gfsenkf_20crV3_cmip5oz_CoriII/</li>
<li>/global/cscratch1/sd/compo/gfsenkf_20crV3_cmip5oz_CoriII/</li>
</ul>
<p>But there is too much output to keep on disc for long, so the output is put into tar files by date, and <a class="reference external" href="http://www.nersc.gov/users/storage-and-file-systems/hpss/storing-and-retrieving-data/clients/hsi-usage/">archived to tape</a> in hsi directory:</p>
<ul class="simple">
<li>/home/projects/incite11/ensda_v451_archive_orig</li>
</ul>
<p>where ‘451’ is the run number.</p>
<p>This data in turn is then cleaned-up, repacked into grib2 format, and copied into another tape archive at</p>
<ul class="simple">
<li>/home/projects/incite11/ensda_v451_archive_grb2_monthly</li>
</ul>
<p>In practice it’s best to use these in reverse order: If the month you want is in the grib2 tape archive, get it from there; otherwise if it’s in the grib1 tabe archive, get it from there; only look on disc if you must have data that’s currently being run.</p>
</div>
<div class="section" id="copy-to-my-own-scratch">
<h2>Copy to my own $SCRATCH<a class="headerlink" href="#copy-to-my-own-scratch" title="Permalink to this headline">¶</a></h2>
<p>If the data are in the grib2 tape archive, copy them to ‘$SCRATCH/20CR_working/ensda_1899/1903/10’ (where 1899, 1903, and 10 are replaced by start year, validity year, and validity month). The <a class="reference internal" href="release_month_from_tape.html"><span class="doc">script to do this</span></a> is called as:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>v3_release/month_from_tape.py --startyear<span class="o">=</span><span class="m">1899</span> --year<span class="o">=</span><span class="m">1903</span> --month<span class="o">=</span><span class="m">10</span> --version<span class="o">=</span>451
</pre></div>
</div>
<p>If the data are not yet in the grib2 archive, but they are in the hsi grib1 archive, then copy them to ‘$SCRATCH/20CR_working_orig/ensda_1899/1903/10’ (replacing start year, validity year, and validity month, as appropriate). The <a class="reference internal" href="orig_month_from_tape.html"><span class="doc">script to do this</span></a> is called with the same options as above:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>v3_orig/month_from_tape.py --startyear<span class="o">=</span><span class="m">1899</span> --year<span class="o">=</span><span class="m">1903</span> --month<span class="o">=</span><span class="m">10</span> --version<span class="o">=</span>451
</pre></div>
</div>
<p>If the data are not yet on tape, only on disc, then they are in grib1 format - copy them directly (‘cp’ command) into the grib1 working directory: ‘$SCRATCH/20CR_working_orig/ensda_1899/1903/10’ (replacing start year, validity year, and validity month, as appropriate).</p>
<p>In all cases the data transfer will take several hours.</p>
</div>
<div class="section" id="strip-output-for-one-variable-and-convert-to-netcdf">
<h2>Strip output for one variable and convert to netCDF<a class="headerlink" href="#strip-output-for-one-variable-and-convert-to-netcdf" title="Permalink to this headline">¶</a></h2>
<p>There are two different sorts of variables in 20CR - analysis variables and forecast variables:</p>
<p>Analysis variables are obtained from the ‘pgrbanl’ files. For the grib2 data, the <a class="reference internal" href="release_extract_anl_var.html"><span class="doc">script that extracts and converts them</span></a> is called as:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>v3_release/extract_anl_var.py --startyear<span class="o">=</span><span class="m">1899</span> --year<span class="o">=</span><span class="m">1903</span> --month<span class="o">=</span><span class="m">10</span> --version<span class="o">=</span><span class="m">451</span> --var<span class="o">=</span>prmsl
</pre></div>
</div>
<p>–var must be one of ‘prmsl’, ‘air.2m’, ‘uwnd.10m’, ‘vwnd.10m’, ‘air.sfc’, and ‘icec’.</p>
<p>Forecast variables are obtained from the ‘pgrbanl’ and ‘pgrbfg’ files. For the grib2 data, the <a class="reference internal" href="release_extract_fg_var.html"><span class="doc">script that extracts and converts them</span></a> is called as:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>v3_release/extract_fg_var.py --startyear<span class="o">=</span><span class="m">1899</span> --year<span class="o">=</span><span class="m">1903</span> --month<span class="o">=</span><span class="m">10</span> --version<span class="o">=</span><span class="m">451</span> --var<span class="o">=</span>prate
</pre></div>
</div>
<p>only –var=prate is currently supported.</p>
<p>For the grib1 data the calls are exactly the same (<a class="reference internal" href="orig_extract_anl_var.html"><span class="doc">analysis</span></a>, <a class="reference internal" href="orig_extract_fg_var.html"><span class="doc">forecast</span></a>), but the scripts are in the ‘v3_orig’ directory.</p>
<p>Whatever the original format, these scripts will create output files of the form ‘$SCRATCH/20CRv3.final/version_4.5.1/1903/10/prmsl.nc’ which are netCDF files similar to those from v2c.</p>
<p>These scripts will also take some time to run (at least 2 hours).</p>
</div>
<div class="section" id="assemble-the-observations-files">
<h2>Assemble the observations files<a class="headerlink" href="#assemble-the-observations-files" title="Permalink to this headline">¶</a></h2>
<p>The observations feedback files are text files (the the format is different to v2c), so it’s just a matter of copying them to the output directory. The <a class="reference internal" href="release_extract_obs.html"><span class="doc">script to do that (for the grib2 data)</span></a> is called as:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>v3_release/extract_obs.py --startyear<span class="o">=</span><span class="m">1899</span> --year<span class="o">=</span><span class="m">1903</span> --month<span class="o">=</span><span class="m">10</span> --version<span class="o">=</span>451
</pre></div>
</div>
<p>and the <a class="reference internal" href="orig_extract_obs.html"><span class="doc">analagous script for grib1</span></a> is in directory v3_orig. Either of these will copy all the observations files to ‘$SCRATCH/20CRv3.final/version_4.5.1/1903/10/observations’.</p>
<p>These scripts only take a couple of minutes to run.</p>
</div>
<div class="section" id="todo">
<h2>ToDo<a class="headerlink" href="#todo" title="Permalink to this headline">¶</a></h2>
<p>These scripts work fine, but the process is fiddly and slow. An obvious improvement is to write a single script that automatically detects the data source, and then runs a sequence of jobs to do the extraction, working in parallel where possible. I failed at this, as running multiple extractions in parallel makes them <strong>very</strong> slow (possibly because of file-system contention). Some cunning will be necessary to produce an efficient script, and so far I have not bothered.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="../tropical-storms/tropical_storms.html" title="Tropical Storms"
             >next</a> |</li>
        <li class="right" >
          <a href="../instructions.html" title="How to use this dataset"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">20CRv3</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    </div>
  </body>
</html>